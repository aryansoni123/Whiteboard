{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sonia\\OneDrive\\Documents\\C\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Hands and Drawing Utilities\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize video capture and set up canvas\n",
    "cap = cv2.VideoCapture(0)\n",
    "canvas = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "\n",
    "# Variables for pen color, thickness, and eraser\n",
    "pen_color = (255, 0, 0)  # Default: blue\n",
    "pen_thickness = 5        # Default thickness\n",
    "eraser_thickness = 70\n",
    "small_eraser_thickness = 15\n",
    "\n",
    "# Define colors\n",
    "colors = {\n",
    "    'red': (0, 0, 255),\n",
    "    'green': (0, 255, 0),\n",
    "    'blue': (255, 0, 0),\n",
    "    'black': (0, 0, 0)\n",
    "}\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "with mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7, min_tracking_confidence=0.7) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        #frame = cv2.resize(frame, (720,1366))\n",
    "        h, w, _ = frame.shape\n",
    "        \n",
    "        # Convert to RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Process the frame and get hand landmarks\n",
    "        results = hands.process(rgb_frame)\n",
    "        cv2.rectangle(frame,(25,80),(135,20),(0, 0, 255),-1)\n",
    "        cv2.rectangle(frame,(155,80),(265,20),(0, 255, 0),-1)\n",
    "        cv2.rectangle(frame,(285,80),(395,20),(255, 0, 0),-1)\n",
    "        cv2.rectangle(frame,(415,80),(525,20),(0, 0, 0),-1)\n",
    "        cv2.circle(frame,(575,50),30,(255,255,255),-1)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # Get landmark positions\n",
    "                landmarks = hand_landmarks.landmark\n",
    "                thumb_tip = landmarks[4]\n",
    "                index_mcp = landmarks[5]\n",
    "                index_pip = landmarks[6]\n",
    "                index_tip = landmarks[8]\n",
    "                ring_tip = landmarks[16]\n",
    "                middle_tip = landmarks[12]\n",
    "                thumb_mcp = landmarks[2]\n",
    "                pinky_mcp = landmarks[17]\n",
    "\n",
    "                # Convert landmarks to pixel positions\n",
    "                thumb_tip_pos = (int(thumb_tip.x * w), int(thumb_tip.y * h))\n",
    "                thumb_mcp_pos = (int(thumb_mcp.x * w), int(thumb_mcp.y * h))\n",
    "                pinky_mcp_pos = (int(pinky_mcp.x * w), int(pinky_mcp.y * h))\n",
    "                index_mcp_pos = (int(index_mcp.x * w), int(index_mcp.y * h))\n",
    "                index_tip_pos = (int(index_tip.x * w), int(index_tip.y * h))\n",
    "                ring_tip_pos = (int(ring_tip.x * w), int(ring_tip.y * h))\n",
    "                middle_tip_pos = (int(middle_tip.x * w), int(middle_tip.y * h))\n",
    "                \n",
    "                flag=False\n",
    "\n",
    "\n",
    "\n",
    "                # Activate pen if thumb tip and middle tip are touching\n",
    "                if (np.linalg.norm(np.array(thumb_tip_pos) - np.array(middle_tip_pos))) < 30 or (np.linalg.norm(np.array(thumb_tip_pos) - np.array(index_tip_pos)))< 30 or (np.linalg.norm(np.array(thumb_tip_pos) - np.array(ring_tip_pos)))< 30:\n",
    "                    cv2.line(canvas, thumb_tip_pos, thumb_tip_pos, pen_color, pen_thickness)\n",
    "                \n",
    "                # Large eraser mode if thumb tip and index MCP are connected\n",
    "                elif np.linalg.norm(np.array(thumb_tip_pos) - np.array(pinky_mcp_pos)) < 30:\n",
    "                    cv2.circle(frame, thumb_tip_pos, eraser_thickness, (0, 0, 0), -1)\n",
    "                    cv2.circle(canvas, thumb_tip_pos, eraser_thickness, (0, 0, 0), -1)\n",
    "                \n",
    "                # Small eraser mode if thumb tip and index PIP are connected\n",
    "                elif np.linalg.norm(np.array(thumb_tip_pos) - np.array(index_tip_pos)) < 30:\n",
    "                    cv2.circle(frame, thumb_tip_pos, small_eraser_thickness, (0, 0, 0), -1)\n",
    "                    cv2.circle(canvas, thumb_tip_pos, small_eraser_thickness, (0, 0, 0), -1)\n",
    "                \n",
    "                # Color and thickness selection\n",
    "                # Red: Thumb tip touches index tip\n",
    "                if np.linalg.norm(np.array(thumb_tip_pos) - np.array(index_tip_pos)) < 30:\n",
    "                    pen_color = colors['red']\n",
    "                # Green: Thumb tip touches middle tip\n",
    "                elif np.linalg.norm(np.array(thumb_tip_pos) - np.array(middle_tip_pos)) < 30:\n",
    "                    pen_color = colors['green']\n",
    "                # Blue: Default color (can be controlled differently)\n",
    "                elif np.linalg.norm(np.array(thumb_tip_pos) - np.array(ring_tip_pos)) < 30:\n",
    "                    pen_color = colors['blue']\n",
    "                    \n",
    "                \n",
    "                \n",
    "                # Thickness control: Can be added based on other gesture logic\n",
    "\n",
    "        # Overlay the canvas on the frame\n",
    "        frame1 = cv2.addWeighted(frame, 0.5, canvas, 0.5, 0)\n",
    "        \n",
    "        # Display the frame\n",
    "        cv2.imshow('Interactive Whiteboard', frame1)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(16.1245154965971)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a=np.array([10,12,30])\n",
    "b=np.array([8,12,14])\n",
    "np.sqrt(np.dot(b-a,b-a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'putText'\n> Overload resolution failed:\n>  - Argument 'lineType' is required to be an integer\n>  - Argument 'lineType' is required to be an integer\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m pvt\u001b[38;5;241m=\u001b[39mcrt\n\u001b[0;32m     18\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m\"\u001b[39m, img)\n\u001b[1;32m---> 19\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mputText\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m70\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFONT_HERSHEY_COMPLEX_SMALL\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'putText'\n> Overload resolution failed:\n>  - Argument 'lineType' is required to be an integer\n>  - Argument 'lineType' is required to be an integer\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "pvt=0\n",
    "crt=0\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "\n",
    "    cvt=time.time()\n",
    "    x=cvt-pvt\n",
    "    fps=1/x\n",
    "    pvt=crt\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.putText(img,str(int(fps)),(10,70),1,1.2,cv2.FONT_HERSHEY_COMPLEX_SMALL,3,(0,255,255),3)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "img = cv2.imread('opencv-course/Resources/Photos/cat.jpg')\n",
    "\n",
    "cv2.imshow('cat', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sonia\\OneDrive\\Documents\\C\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mflip(frame, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     27\u001b[0m frame_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m---> 28\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmp_hands\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_rgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mmulti_hand_landmarks:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hand_landmarks \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mmulti_hand_landmarks:\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;66;03m# Extract thumb tip position (landmark index 4 for thumb tip)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sonia\\OneDrive\\Documents\\C\\.venv\\Lib\\site-packages\\mediapipe\\python\\solutions\\hands.py:153\u001b[0m, in \u001b[0;36mHands.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    133\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the hand landmarks and handedness of each detected hand.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;124;03m         right hand) of the detected hand.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sonia\\OneDrive\\Documents\\C\\.venv\\Lib\\site-packages\\mediapipe\\python\\solution_base.py:340\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    336\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    337\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    338\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Hands and OpenCV\n",
    "mp_hands = mp.solutions.hands.Hands()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pen_color = (0, 255, 0)  # Green color for the pen\n",
    "pen_thickness = 5  # Thickness of the drawn line\n",
    "\n",
    "# Start the webcam feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# List to store the thumb tip positions (for drawing polylines)\n",
    "thumb_points = []\n",
    "\n",
    "# Variable to check hand presence in the previous frame\n",
    "hand_present = False\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    \n",
    "    # Flip the frame for a selfie-view\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = mp_hands.process(frame_rgb)\n",
    "    \n",
    "    if result.multi_hand_landmarks:\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            # Extract thumb tip position (landmark index 4 for thumb tip)\n",
    "            h, w, _ = frame.shape\n",
    "            thumb_tip = hand_landmarks.landmark[4]\n",
    "            thumb_tip_pos = (int(thumb_tip.x * w), int(thumb_tip.y * h))\n",
    "\n",
    "            # If hand was not previously detected, start a new drawing segment\n",
    "            if not hand_present:\n",
    "                thumb_points.append(None)  # Add a break in the drawing\n",
    "\n",
    "            # Append the thumb tip position to the list for drawing\n",
    "            thumb_points.append(thumb_tip_pos)\n",
    "            \n",
    "            # Set hand_present flag to True\n",
    "            hand_present = True\n",
    "            \n",
    "            # Draw hand landmarks (optional)\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp.solutions.hands.HAND_CONNECTIONS)\n",
    "\n",
    "    else:\n",
    "        # If no hand is detected, mark hand_present as False\n",
    "        hand_present = False\n",
    "\n",
    "    # If there are enough points, draw the polyline (persisting the drawing)\n",
    "    if len(thumb_points) > 1:\n",
    "        # Filter out the None values (break points) to avoid connecting them\n",
    "        filtered_points = [pt for pt in thumb_points if pt is not None]\n",
    "        if len(filtered_points) > 1:\n",
    "            pts = np.array(filtered_points, np.int32).reshape((-1, 1, 2))  # Reshape for polylines\n",
    "            cv2.polylines(frame, [pts], isClosed=False, color=pen_color, thickness=pen_thickness)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Drawing with Thumb Tip', frame)\n",
    "    \n",
    "    if cv2.waitKey(5) & 0xFF == 27:  # Exit on pressing 'Esc'\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mflip(frame, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     24\u001b[0m frame_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m---> 25\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmp_hands\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_rgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mmulti_hand_landmarks:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hand_landmarks \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mmulti_hand_landmarks:\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;66;03m# Extract thumb tip position (landmark index 4 for thumb tip)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sonia\\OneDrive\\Documents\\C\\.venv\\Lib\\site-packages\\mediapipe\\python\\solutions\\hands.py:153\u001b[0m, in \u001b[0;36mHands.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    133\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the hand landmarks and handedness of each detected hand.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;124;03m         right hand) of the detected hand.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sonia\\OneDrive\\Documents\\C\\.venv\\Lib\\site-packages\\mediapipe\\python\\solution_base.py:340\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    336\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    337\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    338\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Hands and OpenCV\n",
    "mp_hands = mp.solutions.hands.Hands()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pen_color = (0, 255, 0)  # Green color for the pen\n",
    "pen_thickness = 5  # Thickness of the drawn line\n",
    "\n",
    "# Start the webcam feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# List to store the thumb tip positions (for drawing polylines)\n",
    "thumb_points = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    \n",
    "    # Flip the frame for a selfie-view\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = mp_hands.process(frame_rgb)\n",
    "    \n",
    "    if result.multi_hand_landmarks:\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            # Extract thumb tip position (landmark index 4 for thumb tip)\n",
    "            h, w, _ = frame.shape\n",
    "            thumb_tip = hand_landmarks.landmark[4]\n",
    "            thumb_tip_pos = (int(thumb_tip.x * w), int(thumb_tip.y * h))\n",
    "\n",
    "            # Append the thumb tip position to the list for drawing\n",
    "            thumb_points.append(thumb_tip_pos)\n",
    "            \n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp.solutions.hands.HAND_CONNECTIONS)\n",
    "            # If there are multiple points, draw a polyline\n",
    "    if len(thumb_points) > 1:\n",
    "        pts = np.array(thumb_points, np.int32).reshape((-1, 1, 2))  # Reshape for polylines\n",
    "        cv2.polylines(frame, [pts], isClosed=False, color=pen_color, thickness=pen_thickness)\n",
    "\n",
    "            # Draw hand landmarks (optional)\n",
    "\n",
    "    cv2.imshow('Drawing with Thumb Tip', frame)\n",
    "    \n",
    "    if cv2.waitKey(5) & 0xFF == 27:  # Exit on pressing 'q'\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 54\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# If there are enough points, draw the polyline (persisting the drawing)\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(thumb_points) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 54\u001b[0m     pts \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthumb_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))  \u001b[38;5;66;03m# Reshape for polylines\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mpolylines(frame, [pts], isClosed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, color\u001b[38;5;241m=\u001b[39mpen_color, thickness\u001b[38;5;241m=\u001b[39mpen_thickness)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Display the frame\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Hands and OpenCV\n",
    "mp_hands = mp.solutions.hands.Hands()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pen_color = (0, 255, 0)  # Green color for the pen\n",
    "pen_thickness = 5  # Thickness of the drawn line\n",
    "\n",
    "# Start the webcam feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# List to store the thumb tip positions (for drawing polylines)\n",
    "thumb_points = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    \n",
    "    # Flip the frame for a selfie-view\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = mp_hands.process(frame_rgb)\n",
    "    \n",
    "    if result.multi_hand_landmarks:\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            # Extract thumb tip position (landmark index 4 for thumb tip)\n",
    "            h, w, _ = frame.shape\n",
    "            thumb_tip = hand_landmarks.landmark[4]\n",
    "            thumb_tip_pos = (int(thumb_tip.x * w), int(thumb_tip.y * h))\n",
    "\n",
    "            # Append the thumb tip position to the list for drawing\n",
    "            #thumb_points[0]=thumb_points[1]\n",
    "            \n",
    "            #thumb_points[1]=thumb_tip_pos\n",
    "            \n",
    "            if not hand_present:\n",
    "                thumb_points.append(None)\n",
    "            \n",
    "            thumb_points.append(thumb_tip_pos)\n",
    "\n",
    "            hand_present=True\n",
    "            \n",
    "            # Draw hand landmarks (optional)\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp.solutions.hands.HAND_CONNECTIONS)\n",
    "    \n",
    "    else:\n",
    "        hand_present=False\n",
    "\n",
    "    # If there are enough points, draw the polyline (persisting the drawing)\n",
    "    if len(thumb_points) > 1:\n",
    "        pts = np.array(thumb_points, np.int32).reshape((-1, 1, 2))  # Reshape for polylines\n",
    "        cv2.polylines(frame, [pts], isClosed=False, color=pen_color, thickness=pen_thickness)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Drawing with Thumb Tip', frame)\n",
    "    \n",
    "    if cv2.waitKey(5) & 0xFF == 27:  # Exit on pressing 'Esc'\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'middle_tip_pos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 74\u001b[0m\n\u001b[0;32m     71\u001b[0m pinky_mcp_pos \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m(pinky_mcp\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m*\u001b[39m w), \u001b[38;5;28mint\u001b[39m(pinky_mcp\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m*\u001b[39m h))\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Activate pen if thumb tip and middle tip are touching\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(np\u001b[38;5;241m.\u001b[39marray(thumb_tip_pos) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mmiddle_tip_pos\u001b[49m)) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m30\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(np\u001b[38;5;241m.\u001b[39marray(thumb_tip_pos) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39marray(index_tip_pos)) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m30\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m     76\u001b[0m     np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(np\u001b[38;5;241m.\u001b[39marray(thumb_tip_pos) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39marray(ring_tip_pos)) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m30\u001b[39m):\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# Draw a line from the last position to the current position if previous position exists\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_thumb_pos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mline(canvas, previous_thumb_pos, thumb_tip_pos, pen_color, pen_thickness)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'middle_tip_pos' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Hands and Drawing Utilities\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize video capture and set up canvas\n",
    "cap = cv2.VideoCapture(0)\n",
    "canvas = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "\n",
    "# Variables for pen color, thickness, and eraser\n",
    "pen_color = (255, 0, 0)  # Default: blue\n",
    "pen_thickness = 5        # Default thickness\n",
    "eraser_thickness = 70\n",
    "small_eraser_thickness = 15\n",
    "\n",
    "# Define colors\n",
    "colors = {\n",
    "    'red': (0, 0, 255),\n",
    "    'green': (0, 255, 0),\n",
    "    'blue': (255, 0, 0),\n",
    "    'black': (0, 0, 0)\n",
    "}\n",
    "\n",
    "# Initialize previous thumb position and visibility flag\n",
    "previous_thumb_pos = None\n",
    "hand_visible = False\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "with mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7, min_tracking_confidence=0.7) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        h, w, _ = frame.shape\n",
    "        \n",
    "        # Convert to RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Process the frame and get hand landmarks\n",
    "        results = hands.process(rgb_frame)\n",
    "\n",
    "        # Drawing color and thickness selection rectangles\n",
    "        cv2.rectangle(frame, (25, 80), (135, 20), (0, 0, 255), -1)\n",
    "        cv2.rectangle(frame, (155, 80), (265, 20), (0, 255, 0), -1)\n",
    "        cv2.rectangle(frame, (285, 80), (395, 20), (255, 0, 0), -1)\n",
    "        cv2.rectangle(frame, (415, 80), (525, 20), (0, 0, 0), -1)\n",
    "        cv2.circle(frame, (575, 50), 30, (255, 255, 255), -1)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            hand_visible = True  # Hand is visible\n",
    "\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # Get landmark positions\n",
    "                landmarks = hand_landmarks.landmark\n",
    "                thumb_tip = landmarks[4]\n",
    "                index_mcp = landmarks[5]\n",
    "                index_tip = landmarks[8]\n",
    "                middle_tip = landmarks[12]\n",
    "                ring_tip = landmarks[16]\n",
    "                pinky_mcp = landmarks[17]\n",
    "\n",
    "                # Convert landmarks to pixel positions\n",
    "                thumb_tip_pos = (int(thumb_tip.x * w), int(thumb_tip.y * h))\n",
    "                pinky_mcp_pos = (int(pinky_mcp.x * w), int(pinky_mcp.y * h))\n",
    "\n",
    "                # Activate pen if thumb tip and middle tip are touching\n",
    "                if (np.linalg.norm(np.array(thumb_tip_pos) - np.array(middle_tip_pos)) < 30 or\n",
    "                    np.linalg.norm(np.array(thumb_tip_pos) - np.array(index_tip_pos)) < 30 or\n",
    "                    np.linalg.norm(np.array(thumb_tip_pos) - np.array(ring_tip_pos)) < 30):\n",
    "\n",
    "                    # Draw a line from the last position to the current position if previous position exists\n",
    "                    if previous_thumb_pos is not None:\n",
    "                        cv2.line(canvas, previous_thumb_pos, thumb_tip_pos, pen_color, pen_thickness)\n",
    "\n",
    "                    previous_thumb_pos = thumb_tip_pos  # Update previous position\n",
    "\n",
    "                # Large eraser mode if thumb tip and pinky MCP are connected\n",
    "                if np.linalg.norm(np.array(thumb_tip_pos) - np.array(pinky_mcp_pos)) < 30:\n",
    "                    cv2.circle(frame, thumb_tip_pos, eraser_thickness, (0, 0, 0), -1)\n",
    "                    cv2.circle(canvas, thumb_tip_pos, eraser_thickness, (0, 0, 0), -1)\n",
    "                    previous_thumb_pos = thumb_tip_pos  # Update previous position for erasing\n",
    "\n",
    "                # Small eraser mode if thumb tip and index tip are connected\n",
    "                elif np.linalg.norm(np.array(thumb_tip_pos) - np.array(index_tip_pos)) < 30:\n",
    "                    cv2.circle(frame, thumb_tip_pos, small_eraser_thickness, (0, 0, 0), -1)\n",
    "                    cv2.circle(canvas, thumb_tip_pos, small_eraser_thickness, (0, 0, 0), -1)\n",
    "                    previous_thumb_pos = thumb_tip_pos  # Update previous position for erasing\n",
    "                \n",
    "                # Color selection\n",
    "                if np.linalg.norm(np.array(thumb_tip_pos) - np.array(index_tip_pos)) < 30:\n",
    "                    pen_color = colors['red']\n",
    "                elif np.linalg.norm(np.array(thumb_tip_pos) - np.array(middle_tip_pos)) < 30:\n",
    "                    pen_color = colors['green']\n",
    "                elif np.linalg.norm(np.array(thumb_tip_pos) - np.array(ring_tip_pos)) < 30:\n",
    "                    pen_color = colors['blue']\n",
    "\n",
    "        else:\n",
    "            hand_visible = False  # Hand is not visible\n",
    "            previous_thumb_pos = None  # Reset previous position to prevent connecting lines\n",
    "\n",
    "        # Overlay the canvas on the frame\n",
    "        frame1 = cv2.addWeighted(frame, 0.5, canvas, 0.5, 0)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Interactive Whiteboard', frame1)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
